{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7hXovF2/4kosZcVW0Z1h8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yahiroyudai/DeepLearning2022Late/blob/main/%E5%8F%8E%E9%9B%86%E3%81%97%E3%81%9F%E7%94%BB%E5%83%8F%E3%81%A7%E5%AD%A6%E7%BF%92%E3%81%A8%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#収集した画像をColabにUPして学習させ、それをもとに分類させる"
      ],
      "metadata": {
        "id": "IXKEULxuV35g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4Ll2ZU46iiKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ファイルのフォルダを準備する"
      ],
      "metadata": {
        "id": "qUHD2lY0WU24"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6rjYTFzfVDyy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('sample', exist_ok = True) #分類対象の画像のフォルダを作成\n",
        "os.makedirs('output/dog/sample', exist_ok = True) #犬と判定された時の置き場所\n",
        "os.makedirs('output/cat/sample', exist_ok = True) #猫と判定された時の置き場所\n",
        "os.makedirs('img/deep_learning/dog', exist_ok = True) #犬の学習用の収集画像\n",
        "os.makedirs('img/deep_learning/cat', exist_ok = True) #猫の学習用の収集画像"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##必要なライブラリをimport"
      ],
      "metadata": {
        "id": "yhuWCF6vYZe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "Dwl40-CzYYz8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##分類(クラス)の名前をフォルダ名(dog, cat)から引用する"
      ],
      "metadata": {
        "id": "0rMjOW0OZkhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"img/deep_learning\" #dogとcatフォルダがある場所\n",
        "folders = os.listdir(path)\n",
        "#2つのパスからフォルダ名を抜き出す\n",
        "classes = [f for f in folders if os.path.isdir(os.path.join(path, f))]\n",
        "print(classes)\n",
        "n_classes = len(classes)\n",
        "print(n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jff5z0vZeC3",
        "outputId": "2298c254-c90f-4f71-f992-e17f6ce57b68"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dog', 'cat']\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##画像を読み込みリサイズ、整形する"
      ],
      "metadata": {
        "id": "9qBB3Cbc9tqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#画像とラベルのための配列\n",
        "X = [ ] #画像(学習用データ用の配列)\n",
        "Y = [ ] #ラベル(正解用の配列)\n",
        "\n",
        "#画像を読み込みつつリサイズする\n",
        "for label, class_name in enumerate(classes):\n",
        "  files = glob.glob(path + \"/\" + class_name + \"/*jpg\")\n",
        "  for file in files:\n",
        "    img = cv2.imread(file)\n",
        "    img = cv2.resize(img, dsize = (224, 224))\n",
        "    X.append(img)\n",
        "    Y.append(label)\n",
        "    #内部ループ終わり\n",
        "#外部ループ終わり"
      ],
      "metadata": {
        "id": "LlpcklZKbie_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##0〜255のビットデータ値を、学習のために0~1に変換(正規化)学習精度を上げるセクション"
      ],
      "metadata": {
        "id": "Yz0bpiCVFUgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X) #配列XをNumpy配列に変換\n",
        "X = X.astype('float32') #少数型に変換\n",
        "X /= 255.0\n",
        "#ラベルもnumpyの配列に変換\n",
        "Y = np.array(Y)\n",
        "Y = np_utils.to_categorical(Y, n_classes)"
      ],
      "metadata": {
        "id": "Wh5wzZhJENgM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##整形したデータを学習用とテスト検証用に振り分ける"
      ],
      "metadata": {
        "id": "3c3FrTnSGW01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#学習データ８割、テスト検証用２割に分ける\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
        "#学習データ８割(画像問題データ)\n",
        "print(X_train.shape)\n",
        "#テスト検証用２割(画像問題データ)\n",
        "print(X_test.shape)\n",
        "#学習データ８割(正解ラベル)\n",
        "print(Y_train.shape)\n",
        "#テスト検証用２割(正解ラベル)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkdD9JkJGi_j",
        "outputId": "bc982fcc-2fe3-4ec2-ae87-be0143403df7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 224, 224, 3)\n",
            "(31, 224, 224, 3)\n",
            "(120, 2)\n",
            "(31, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#準備したデータを学習させていく"
      ],
      "metadata": {
        "id": "9cCWJXwELdbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##学習に必要なライブラリをimport\n"
      ],
      "metadata": {
        "id": "5x6TJiwXLc-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Activation, Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "dfX0FD-CIMMP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##モデルのVGG16をアレンジしていく"
      ],
      "metadata": {
        "id": "Zrl5Ic12TE52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG16入力層を用意する(定義する)\n",
        "input_tensor = Input(shape = (224, 224, 3))\n",
        "#VGG16のインスタンスを作る(最後のsoftmaxの1000層を無効にして省く)\n",
        "base_model = VGG16(weights = 'imagenet', input_tensor = input_tensor, include_top = False)"
      ],
      "metadata": {
        "id": "kn35oSVmMcXD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1000分類のsoftmaxを外した代わりに、2つに分類するsoftmax層を追加する"
      ],
      "metadata": {
        "id": "hk7m6xuYXa5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.serialization import activation\n",
        "#追加する層の作成\n",
        "top_model = Sequential( ) #ラッピングする層\n",
        "top_model.add(Flatten(input_shape = base_model.output_shape[1:]))\n",
        "top_model.add(Dense(n_classes, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "o56reIEPXSy_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##最後のSOFTMAXを外したモデル(basemodel)と追加用の2つに分類するSOFTMAX層のモデ(top_mode）をつなげる"
      ],
      "metadata": {
        "id": "zUXvlWFwaas9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model (inputs = base_model.input, outputs=top_model(base_model.output) )"
      ],
      "metadata": {
        "id": "ENso24BsZBqx"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##時間短縮のために、15層までを外す"
      ],
      "metadata": {
        "id": "HssWKRjDbSee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ループしながら15層までを無効にする\n",
        "for layer in model.layers[:15]:\n",
        "  layer.trainable = False #15層までは学習しない\n",
        "#ループ終わり\n",
        "print('#layers =', len(model.layers))#モデルの層の数を表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZnJKEuMbMfe",
        "outputId": "5a735bdd-fe41-4550-c65d-7b6a07b8950b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#layers = 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##学習モデルをコンパイルする"
      ],
      "metadata": {
        "id": "3oA8vSAfcedn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#損失はクロスエントロビー法で算出、製品化はADAM、指標は精度でみる\n",
        "model.compile(loss= 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "-tIc8dW8cdqP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##コンパイルしたモデルを表示"
      ],
      "metadata": {
        "id": "omDpEXKUe8io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrFNxZ7ievxW",
        "outputId": "c8cc74ee-99b8-4b0a-a52e-71c96c581ed2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 2)                 50178     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 7,129,602\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##コンパイルしたモデルで取集した画像データを学習させる"
      ],
      "metadata": {
        "id": "rlm-cg00fZiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,Y_train,epochs=20,batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nufXOG_gfAGj",
        "outputId": "29bd8a8a-9184-4524-baf3-f9f0b5b3274c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 2s 99ms/step - loss: 1.8317 - accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 0.6985 - accuracy: 0.5333\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 0.7131 - accuracy: 0.4833\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.6931 - accuracy: 0.5083\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 0.6931 - accuracy: 0.5083\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.6931 - accuracy: 0.5167\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.6930 - accuracy: 0.5167\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.7290 - accuracy: 0.5167\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.7010 - accuracy: 0.5083\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.6929 - accuracy: 0.5167\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.6929 - accuracy: 0.5167\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.6929 - accuracy: 0.5167\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.6929 - accuracy: 0.5167\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.6929 - accuracy: 0.5167\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.6929 - accuracy: 0.5167\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.6929 - accuracy: 0.5167\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.6928 - accuracy: 0.5167\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.6928 - accuracy: 0.5167\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.6928 - accuracy: 0.5167\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a843e5700>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##学習の成果を指標(accuracy)で確認"
      ],
      "metadata": {
        "id": "-4jOG5b5iGG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cfh7245rhDFc",
        "outputId": "3c124f6a-2460-4055-90bf-d6824260bc75"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 102ms/step - loss: 0.6954 - accuracy: 0.4194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##作成した学習モデルとクラス分類名を保存"
      ],
      "metadata": {
        "id": "U43QYfyJizlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# オブジェクトをバイナリファイルで保存\n",
        "pickle.dump(classes,open('classes.sav','wb'))\n",
        "# 学習モデルの保存\n",
        "model.save('cnn.h5')"
      ],
      "metadata": {
        "id": "iJx2Tk91iQzC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##保存したクラス分類と学習モデルを読み込んで使う"
      ],
      "metadata": {
        "id": "1kWcJSNrlOYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ライブラリのimport\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "import cv2\n",
        "import glob"
      ],
      "metadata": {
        "id": "JO2JKbawlysZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ファイルを読み込んでオブジェクトとして蘇らせる\n"
      ],
      "metadata": {
        "id": "yazxF6JSjh1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('cnn.h5')\n",
        "classes = pickle.load(open('classes.sav', 'rb'))"
      ],
      "metadata": {
        "id": "LfzwNhG9mp3A"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##sample画像を読み込む"
      ],
      "metadata": {
        "id": "I2L5l1IJUhh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob('sample/*')"
      ],
      "metadata": {
        "id": "YAf5ZClRP_L2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ファイルパスから画像を読み込み、学習モデルに判定させ、該当するoutputフォルダにコピーを書き込む"
      ],
      "metadata": {
        "id": "EuRFxCjoXOW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in files:#ファイルの数だけループ\n",
        "  img = cv2.imread (file) # 画像データを読み込み\n",
        "  # 判定のためにimgを加工したimg2を作る\n",
        "  img2 = cv2.resize(img, dsize= (224, 224)) #(224, 224)にリサイズ\n",
        "  img2 = img2.astype ('float32')\n",
        "  img2 = img2/255.0 # 0.0〜255.0 だったデータを0.0〜1.0に変換\n",
        "  img2 = img2 [None, ...] # 1次元配列に変換\n",
        "  #正規化したデータを判定\n",
        "  result = model. predict (img2)\n",
        "  print(result) #画面に生で出力\n",
        "  #確率が高いクラスを取得\n",
        "  pred = result.argmax()\n",
        "  print(pred, str(classes[pred]))\n",
        "  #判定したクラス分類のフォルダのほうに、画像データを書き込む\n",
        "  cv2.imwrite ('output/' + str (classes [pred]) + '/' + file, img)\n",
        "#ループ終わり"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC5MVKaVXM16",
        "outputId": "edecd318-7ec3-4081-aa57-957cc598668a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "[[0.49315956 0.5068404 ]]\n",
            "1 cat\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "[[0.49315956 0.5068404 ]]\n",
            "1 cat\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "[[0.49315956 0.5068404 ]]\n",
            "1 cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Ei_jVeGYl81"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}